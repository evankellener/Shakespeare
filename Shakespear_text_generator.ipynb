{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evankellener/Shakespeare/blob/main/Shakespear_text_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QizeXyMGO0Kw"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "  shakespear_text = response.text\n",
        "else:\n",
        "  print(\"Failed to receive dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyPlmA-KO5nL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvi6Dvh8O-l7"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Shakespear/shakespear.txt', 'w', encoding = 'utf-8') as file:\n",
        "  file.write(shakespear_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Che5t2qhN5qi"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Shakespear/shakespear.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "# set text to your own text file\n",
        "\n",
        "# Create a set of unique characters\n",
        "chars = sorted(list(set(text)))\n",
        "\n",
        "# Create character-to-integer and integer-to-character mappings\n",
        "char_to_int = {c: i for i, c in enumerate(chars)}\n",
        "int_to_char = {i: c for i, c in enumerate(chars)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-La4sFktPdY9"
      },
      "outputs": [],
      "source": [
        "sequence_length = 100\n",
        "X_data = []\n",
        "y_data = []\n",
        "\n",
        "for i in range(0, len(text) - sequence_length, 1):\n",
        "    seq_in = text[i:i + sequence_length]\n",
        "    seq_out = text[i + sequence_length]\n",
        "    X_data.append([char_to_int[char] for char in seq_in])\n",
        "    y_data.append(char_to_int[seq_out])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2UT16LmQWIT"
      },
      "outputs": [],
      "source": [
        "print(len(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eirir_yyPnPN"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "embedding_dim = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(chars), output_dim=embedding_dim, input_length=sequence_length))\n",
        "model.add(LSTM(256, kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fQTeTFmP0Hz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "X = np.array(X_data)\n",
        "y = to_categorical(y_data, num_classes = len(chars))\n",
        "\n",
        "split_index = int(0.8 * len(X))  # 80% of data for training\n",
        "\n",
        "X_train = X[:split_index]\n",
        "y_train = y[:split_index]\n",
        "\n",
        "X_val = X[split_index:]\n",
        "y_val = y[split_index:]\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=128, validation_data=(X_val, y_val), callbacks = [early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb36DLPbo47D"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/Shakespear/shakespear_v3.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fri-iWlN0S7I"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, char_to_int, int_to_char, seed_text, num_chars_to_generate=500):\n",
        "    generated_text = seed_text\n",
        "    input_sequence = [char_to_int[char] for char in seed_text]\n",
        "\n",
        "    for _ in range(num_chars_to_generate):\n",
        "        # Ensure the input sequence is of length 100\n",
        "        while len(input_sequence) < 100:\n",
        "            input_sequence.insert(0, 0)  # pad with zeros at the beginning\n",
        "\n",
        "        # Prepare the input data\n",
        "        input_data = np.reshape(input_sequence, (1, len(input_sequence)))\n",
        "\n",
        "        # Predict the next character\n",
        "        prediction = model.predict(input_data, verbose=0)\n",
        "        index = sample(prediction[0], temperature=0.5)\n",
        "        predicted_char = int_to_char[index]\n",
        "\n",
        "        # Append the predicted character to the generated text and update the input sequence\n",
        "        generated_text += predicted_char\n",
        "        input_sequence.append(index)\n",
        "        input_sequence = input_sequence[1:]\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds + 1e-7) / temperature  # Adding a small value to avoid log(0)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cz8z1RHt0xDn"
      },
      "outputs": [],
      "source": [
        "seed_text = \"to be or not to be\"\n",
        "output = generate_text(model, char_to_int, int_to_char, seed_text)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "youp-j4J2b6U"
      },
      "source": [
        "Additions\n",
        "\n",
        "temperature sample: gave somewhat intelligable text\n",
        "\n",
        "epochs from 10 -> 20 best val loss = 1.5144\n",
        "\n",
        "used validation_data=(X_val, y_val) instead of validation split = 0.2"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMWLwhn72eB1BPfbzhNJ5da",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}